{"ast":null,"code":"\"use strict\";\n\n/*\r\n * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.\r\n */\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Chat = void 0;\nconst chatComplete_js_1 = require(\"../funcs/chatComplete.js\");\nconst chatStream_js_1 = require(\"../funcs/chatStream.js\");\nconst sdks_js_1 = require(\"../lib/sdks.js\");\nconst fp_js_1 = require(\"../types/fp.js\");\nclass Chat extends sdks_js_1.ClientSDK {\n  /**\r\n   * Chat Completion\r\n   */\n  async complete(request, options) {\n    return (0, fp_js_1.unwrapAsync)((0, chatComplete_js_1.chatComplete)(this, request, options));\n  }\n  /**\r\n   * Stream chat completion\r\n   *\r\n   * @remarks\r\n   * Mistral AI provides the ability to stream responses back to a client in order to allow partial results for certain requests. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.\r\n   */\n  async stream(request, options) {\n    return (0, fp_js_1.unwrapAsync)((0, chatStream_js_1.chatStream)(this, request, options));\n  }\n}\nexports.Chat = Chat;","map":{"version":3,"names":["chatComplete_js_1","require","chatStream_js_1","sdks_js_1","fp_js_1","Chat","ClientSDK","complete","request","options","unwrapAsync","chatComplete","stream","chatStream","exports"],"sources":["C:\\Users\\silvi\\OneDrive\\Escritorio\\LUISDEEEE\\School of code\\week 13\\final-project-the-visualisers\\node_modules\\@mistralai\\mistralai\\src\\sdk\\chat.ts"],"sourcesContent":["/*\r\n * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.\r\n */\r\n\r\nimport { chatComplete } from \"../funcs/chatComplete.js\";\r\nimport { chatStream } from \"../funcs/chatStream.js\";\r\nimport { EventStream } from \"../lib/event-streams.js\";\r\nimport { ClientSDK, RequestOptions } from \"../lib/sdks.js\";\r\nimport * as components from \"../models/components/index.js\";\r\nimport { unwrapAsync } from \"../types/fp.js\";\r\n\r\nexport class Chat extends ClientSDK {\r\n  /**\r\n   * Chat Completion\r\n   */\r\n  async complete(\r\n    request: components.ChatCompletionRequest,\r\n    options?: RequestOptions,\r\n  ): Promise<components.ChatCompletionResponse> {\r\n    return unwrapAsync(chatComplete(\r\n      this,\r\n      request,\r\n      options,\r\n    ));\r\n  }\r\n\r\n  /**\r\n   * Stream chat completion\r\n   *\r\n   * @remarks\r\n   * Mistral AI provides the ability to stream responses back to a client in order to allow partial results for certain requests. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.\r\n   */\r\n  async stream(\r\n    request: components.ChatCompletionStreamRequest,\r\n    options?: RequestOptions,\r\n  ): Promise<EventStream<components.CompletionEvent>> {\r\n    return unwrapAsync(chatStream(\r\n      this,\r\n      request,\r\n      options,\r\n    ));\r\n  }\r\n}\r\n"],"mappings":";;AAAA;;;;;;;AAIA,MAAAA,iBAAA,GAAAC,OAAA;AACA,MAAAC,eAAA,GAAAD,OAAA;AAEA,MAAAE,SAAA,GAAAF,OAAA;AAEA,MAAAG,OAAA,GAAAH,OAAA;AAEA,MAAaI,IAAK,SAAQF,SAAA,CAAAG,SAAS;EACjC;;;EAGA,MAAMC,QAAQA,CACZC,OAAyC,EACzCC,OAAwB;IAExB,OAAO,IAAAL,OAAA,CAAAM,WAAW,EAAC,IAAAV,iBAAA,CAAAW,YAAY,EAC7B,IAAI,EACJH,OAAO,EACPC,OAAO,CACR,CAAC;EACJ;EAEA;;;;;;EAMA,MAAMG,MAAMA,CACVJ,OAA+C,EAC/CC,OAAwB;IAExB,OAAO,IAAAL,OAAA,CAAAM,WAAW,EAAC,IAAAR,eAAA,CAAAW,UAAU,EAC3B,IAAI,EACJL,OAAO,EACPC,OAAO,CACR,CAAC;EACJ;;AA9BFK,OAAA,CAAAT,IAAA,GAAAA,IAAA","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}