{"ast":null,"code":"\"use strict\";\n\n/*\n * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.\n */\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Chat = void 0;\nconst chatComplete_js_1 = require(\"../funcs/chatComplete.js\");\nconst chatStream_js_1 = require(\"../funcs/chatStream.js\");\nconst sdks_js_1 = require(\"../lib/sdks.js\");\nconst fp_js_1 = require(\"../types/fp.js\");\nclass Chat extends sdks_js_1.ClientSDK {\n  /**\n   * Chat Completion\n   */\n  async complete(request, options) {\n    return (0, fp_js_1.unwrapAsync)((0, chatComplete_js_1.chatComplete)(this, request, options));\n  }\n  /**\n   * Stream chat completion\n   *\n   * @remarks\n   * Mistral AI provides the ability to stream responses back to a client in order to allow partial results for certain requests. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.\n   */\n  async stream(request, options) {\n    return (0, fp_js_1.unwrapAsync)((0, chatStream_js_1.chatStream)(this, request, options));\n  }\n}\nexports.Chat = Chat;","map":{"version":3,"names":["chatComplete_js_1","require","chatStream_js_1","sdks_js_1","fp_js_1","Chat","ClientSDK","complete","request","options","unwrapAsync","chatComplete","stream","chatStream","exports"],"sources":["/Users/emilijablinkeviciute/Desktop/REPOS/Visualisers project/final-project-the-visualisers/my-app/node_modules/@mistralai/mistralai/src/sdk/chat.ts"],"sourcesContent":["/*\n * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.\n */\n\nimport { chatComplete } from \"../funcs/chatComplete.js\";\nimport { chatStream } from \"../funcs/chatStream.js\";\nimport { EventStream } from \"../lib/event-streams.js\";\nimport { ClientSDK, RequestOptions } from \"../lib/sdks.js\";\nimport * as components from \"../models/components/index.js\";\nimport { unwrapAsync } from \"../types/fp.js\";\n\nexport class Chat extends ClientSDK {\n  /**\n   * Chat Completion\n   */\n  async complete(\n    request: components.ChatCompletionRequest,\n    options?: RequestOptions,\n  ): Promise<components.ChatCompletionResponse> {\n    return unwrapAsync(chatComplete(\n      this,\n      request,\n      options,\n    ));\n  }\n\n  /**\n   * Stream chat completion\n   *\n   * @remarks\n   * Mistral AI provides the ability to stream responses back to a client in order to allow partial results for certain requests. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.\n   */\n  async stream(\n    request: components.ChatCompletionStreamRequest,\n    options?: RequestOptions,\n  ): Promise<EventStream<components.CompletionEvent>> {\n    return unwrapAsync(chatStream(\n      this,\n      request,\n      options,\n    ));\n  }\n}\n"],"mappings":";;AAAA;;;;;;;AAIA,MAAAA,iBAAA,GAAAC,OAAA;AACA,MAAAC,eAAA,GAAAD,OAAA;AAEA,MAAAE,SAAA,GAAAF,OAAA;AAEA,MAAAG,OAAA,GAAAH,OAAA;AAEA,MAAaI,IAAK,SAAQF,SAAA,CAAAG,SAAS;EACjC;;;EAGA,MAAMC,QAAQA,CACZC,OAAyC,EACzCC,OAAwB;IAExB,OAAO,IAAAL,OAAA,CAAAM,WAAW,EAAC,IAAAV,iBAAA,CAAAW,YAAY,EAC7B,IAAI,EACJH,OAAO,EACPC,OAAO,CACR,CAAC;EACJ;EAEA;;;;;;EAMA,MAAMG,MAAMA,CACVJ,OAA+C,EAC/CC,OAAwB;IAExB,OAAO,IAAAL,OAAA,CAAAM,WAAW,EAAC,IAAAR,eAAA,CAAAW,UAAU,EAC3B,IAAI,EACJL,OAAO,EACPC,OAAO,CACR,CAAC;EACJ;;AA9BFK,OAAA,CAAAT,IAAA,GAAAA,IAAA","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}